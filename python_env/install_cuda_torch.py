#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CUDAç‰ˆæœ¬torchå®‰è£…è„šæœ¬
ä¸“é—¨ç”¨äºå®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
"""

import sys
import os
import subprocess
import shutil
import platform
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

from python_launcher import get_python_executable, install_package, uninstall_package, check_package_installed

def detect_cuda_version():
    """æ£€æµ‹CUDAç‰ˆæœ¬"""
    nvidia_smi = shutil.which("nvidia-smi")
    if nvidia_smi:
        try:
            # åœ¨Windowsä¸Šä½¿ç”¨cp936ç¼–ç ï¼ˆGBKï¼‰ï¼Œåœ¨å…¶ä»–ç³»ç»Ÿä½¿ç”¨utf-8
            if platform.system().lower() == 'windows':
                encoding = 'cp936'
            else:
                encoding = 'utf-8'
            
            result = subprocess.run(
                [nvidia_smi, "--version"],
                capture_output=True,
                text=True,
                encoding=encoding,
                errors='ignore'
            )
            
            if result.returncode == 0 and "CUDA Version" in result.stdout:
                for line in result.stdout.splitlines():
                    if "CUDA Version" in line:
                        parts = line.split("CUDA Version")
                        if len(parts) > 1:
                            version_part = parts[1].strip()
                            import re
                            version_match = re.search(r'(\d+\.\d+)', version_part)
                            if version_match:
                                return version_match.group(1)
        except:
            pass
    
    return None

def install_cuda_torch():
    """å®‰è£…CUDAç‰ˆæœ¬çš„torch"""
    print("=== å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch ===")
    
    python_exe = get_python_executable()
    print(f"ä½¿ç”¨Python: {python_exe}")
    
    # æ£€æµ‹CUDAç‰ˆæœ¬
    cuda_version = detect_cuda_version()
    if not cuda_version:
        print("âŒ æœªæ£€æµ‹åˆ°CUDAï¼Œæ— æ³•å®‰è£…CUDAç‰ˆæœ¬çš„torch")
        return False
    
    print(f"æ£€æµ‹åˆ°CUDAç‰ˆæœ¬: {cuda_version}")
    
    # å¸è½½ç°æœ‰çš„torch
    print("\n1. å¸è½½ç°æœ‰çš„torch...")
    packages_to_remove = ["torch", "torchvision", "torchaudio"]
    for package in packages_to_remove:
        if check_package_installed(package):
            print(f"å¸è½½ {package}...")
            uninstall_package(package)
    
    # æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©å®‰è£…å‘½ä»¤
    major_minor = ".".join(cuda_version.split(".")[:2])
    print(f"\n2. å®‰è£…CUDA {major_minor} å…¼å®¹ç‰ˆæœ¬çš„torch...")
    
    if major_minor.startswith("12.8") or major_minor.startswith("12.7") or major_minor.startswith("12.6"):
        print("å®‰è£…CUDA 12.1å…¼å®¹ç‰ˆæœ¬...")
        index_url = "https://download.pytorch.org/whl/cu121"
    elif major_minor.startswith("12.1"):
        print("å®‰è£…CUDA 12.1ç‰ˆæœ¬...")
        index_url = "https://download.pytorch.org/whl/cu121"
    elif major_minor.startswith("12.0"):
        print("å®‰è£…CUDA 12.0ç‰ˆæœ¬...")
        index_url = "https://download.pytorch.org/whl/cu120"
    elif major_minor.startswith("11.8"):
        print("å®‰è£…CUDA 11.8ç‰ˆæœ¬...")
        index_url = "https://download.pytorch.org/whl/cu118"
    else:
        print("å®‰è£…CPUç‰ˆæœ¬...")
        index_url = "https://download.pytorch.org/whl/cpu"
    
    # å®‰è£…torch
    packages_to_install = ["torch", "torchvision", "torchaudio"]
    success = True
    
    for package in packages_to_install:
        print(f"\nå®‰è£… {package}...")
        if not install_package(package, index_url):
            success = False
            break
    
    if success:
        print("\n3. éªŒè¯å®‰è£…...")
        try:
            result = subprocess.run(
                [python_exe, "-c", """
import torch
print(f'torchç‰ˆæœ¬: {torch.__version__}')
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')
    print(f'GPUæ•°é‡: {torch.cuda.device_count()}')
    if torch.cuda.device_count() > 0:
        print(f'GPUåç§°: {torch.cuda.get_device_name(0)}')
        
        # æµ‹è¯•GPUè®¡ç®—
        print('æµ‹è¯•GPUè®¡ç®—...')
        x = torch.randn(3, 3).cuda()
        y = x * 2
        result = y.cpu()
        print(f'GPUè®¡ç®—æµ‹è¯•æˆåŠŸ: {result[0, 0].item():.4f}')
else:
    print('CUDAä¸å¯ç”¨')
                """],
                capture_output=True,
                text=True,
                encoding='utf-8',
                errors='replace'
            )
            
            if result.returncode == 0:
                print("âœ… éªŒè¯ç»“æœ:")
                print(result.stdout)
                return True
            else:
                print(f"âŒ éªŒè¯å¤±è´¥: {result.stderr}")
                return False
                
        except Exception as e:
            print(f"âŒ éªŒè¯å¤±è´¥: {e}")
            return False
    else:
        print("âŒ torchå®‰è£…å¤±è´¥")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("å¼€å§‹å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch...")
    print("=" * 50)
    
    success = install_cuda_torch()
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ CUDAç‰ˆæœ¬torchå®‰è£…æˆåŠŸï¼")
        print("ç°åœ¨PyTorchå¯ä»¥æ­£å¸¸ä½¿ç”¨GPUäº†ï¼")
    else:
        print("âŒ CUDAç‰ˆæœ¬torchå®‰è£…å¤±è´¥")

if __name__ == "__main__":
    main()
